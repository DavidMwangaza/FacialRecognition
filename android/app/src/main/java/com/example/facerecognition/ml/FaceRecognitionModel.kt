package com.example.facerecognition.ml

import android.content.Context
import android.graphics.Bitmap
import android.util.Log
import com.google.gson.Gson
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.support.common.FileUtil
import java.io.BufferedReader
import java.io.InputStreamReader
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlin.math.exp
import kotlin.math.sqrt

/**
 * Classe pour g√©rer l'inf√©rence du mod√®le TensorFlow Lite
 * Reconnaissance faciale hors ligne
 */
class FaceRecognitionModel(private val context: Context) {
    
    private var interpreter: Interpreter? = null
    private var labels: List<String> = emptyList()
    private var inputShape: IntArray = intArrayOf(1, 512)
    private var outputShape: IntArray = intArrayOf(1, 2)
    
    companion object {
        private const val TAG = "FaceRecognitionModel"
        private const val MODEL_FILE = "face_recognition_model.tflite"
        private const val METADATA_FILE = "face_recognition_metadata.json"
        private const val BATCH_SIZE = 1
        private const val EMBEDDING_SIZE = 512
    }
    
    data class ModelMetadata(
        val names: List<String>,
        val num_classes: Int,
        val input_shape: List<Int>,
        val model_type: String
    )
    
    data class RecognitionResult(
        val name: String,
        val confidence: Float,
        val classIndex: Int
    )
    
    init {
        loadModel()
        loadMetadata()
    }
    
    /**
     * Charge le mod√®le TensorFlow Lite
     */
    private fun loadModel() {
        try {
            Log.d(TAG, "üì¶ Chargement du mod√®le: $MODEL_FILE")
            
            // V√©rifier que le fichier existe
            val assetFiles = context.assets.list("") ?: emptyArray()
            Log.d(TAG, "üìÇ Fichiers assets disponibles: ${assetFiles.joinToString()}")
            
            val options = Interpreter.Options().apply {
                setNumThreads(4)
                setUseNNAPI(true) // Utiliser Neural Networks API si disponible
            }
            
            val modelBuffer = FileUtil.loadMappedFile(context, MODEL_FILE)
            Log.d(TAG, "‚úì Buffer mod√®le charg√©: ${modelBuffer.capacity()} bytes")
            
            interpreter = Interpreter(modelBuffer, options)
            Log.d(TAG, "‚úì Interpreter cr√©√©")
            
            // R√©cup√©rer les dimensions du mod√®le
            val inputTensor = interpreter?.getInputTensor(0)
            val outputTensor = interpreter?.getOutputTensor(0)
            
            inputShape = inputTensor?.shape() ?: inputShape
            outputShape = outputTensor?.shape() ?: outputShape
            
            Log.d(TAG, "‚úì Mod√®le charg√© avec succ√®s")
            Log.d(TAG, "  Input shape: ${inputShape.contentToString()}")
            Log.d(TAG, "  Output shape: ${outputShape.contentToString()}")
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erreur lors du chargement du mod√®le: ${e.message}", e)
            e.printStackTrace()
            throw e // Propager l'erreur pour qu'elle soit visible
        }
    }
    
    /**
     * Charge les m√©tadonn√©es (noms des classes)
     */
    private fun loadMetadata() {
        try {
            Log.d(TAG, "üìã Chargement m√©tadonn√©es: $METADATA_FILE")
            
            val jsonString = context.assets.open(METADATA_FILE).use { inputStream ->
                BufferedReader(InputStreamReader(inputStream)).use { reader ->
                    reader.readText()
                }
            }
            
            Log.d(TAG, "üìÑ JSON lu: $jsonString")
            
            val gson = Gson()
            val metadata = gson.fromJson(jsonString, ModelMetadata::class.java)
            
            labels = metadata.names
            
            Log.d(TAG, "‚úì M√©tadonn√©es charg√©es")
            Log.d(TAG, "  Nombre de classes: ${labels.size}")
            Log.d(TAG, "  Labels: $labels")
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erreur lors du chargement des m√©tadonn√©es: ${e.message}", e)
            e.printStackTrace()
            // Labels par d√©faut si √©chec
            labels = List(outputShape[1]) { "Personne $it" }
        }
    }
    
    /**
     * Extrait un embedding depuis une image de visage
     * Pour l'instant, g√©n√®re un embedding factice bas√© sur les pixels
     * TODO: Utiliser un vrai mod√®le d'extraction d'embeddings (FaceNet, ArcFace, etc.)
     */
    private fun extractEmbedding(bitmap: Bitmap): FloatArray {
        // Redimensionner √† 112x112 (taille standard pour FaceNet)
        val resizedBitmap = Bitmap.createScaledBitmap(bitmap, 112, 112, true)
        
        // Extraire les caract√©ristiques moyennes des pixels
        val pixels = IntArray(112 * 112)
        resizedBitmap.getPixels(pixels, 0, 112, 0, 0, 112, 112)
        
        // Cr√©er un embedding simple bas√© sur les statistiques de l'image
        val embedding = FloatArray(EMBEDDING_SIZE)
        
        // Calculer des caract√©ristiques de base
        val blockSize = 8
        val numBlocks = 112 / blockSize
        
        for (i in 0 until numBlocks) {
            for (j in 0 until numBlocks) {
                val blockIndex = i * numBlocks + j
                if (blockIndex < EMBEDDING_SIZE) {
                    var sum = 0f
                    for (y in 0 until blockSize) {
                        for (x in 0 until blockSize) {
                            val pixelIndex = (i * blockSize + y) * 112 + (j * blockSize + x)
                            if (pixelIndex < pixels.size) {
                                val pixel = pixels[pixelIndex]
                                val r = ((pixel shr 16) and 0xFF) / 255.0f
                                val g = ((pixel shr 8) and 0xFF) / 255.0f
                                val b = (pixel and 0xFF) / 255.0f
                                sum += (r + g + b) / 3.0f
                            }
                        }
                    }
                    embedding[blockIndex] = sum / (blockSize * blockSize)
                }
            }
        }
        
        // Normalisation L2
        var norm = 0f
        for (value in embedding) {
            norm += value * value
        }
        norm = kotlin.math.sqrt(norm)
        
        if (norm > 0) {
            for (i in embedding.indices) {
                embedding[i] /= norm
            }
        }
        
        return embedding
    }
    
    /**
     * Effectue la reconnaissance faciale √† partir d'une image
     */
    fun recognize(faceBitmap: Bitmap): RecognitionResult? {
        if (interpreter == null) {
            Log.e(TAG, "Mod√®le non charg√©")
            return null
        }
        
        try {
            // Extraire l'embedding de l'image
            val embedding = extractEmbedding(faceBitmap)
            
            // Cr√©er le buffer d'entr√©e
            val inputBuffer = ByteBuffer.allocateDirect(BATCH_SIZE * EMBEDDING_SIZE * 4)
            inputBuffer.order(ByteOrder.nativeOrder())
            for (value in embedding) {
                inputBuffer.putFloat(value)
            }
            
            // Pr√©parer le buffer de sortie
            val numClasses = outputShape[1]
            val outputBuffer = Array(BATCH_SIZE) { FloatArray(numClasses) }
            
            // Ex√©cuter l'inf√©rence
            interpreter?.run(inputBuffer, outputBuffer)
            
            // Analyser les r√©sultats
            val probabilities = outputBuffer[0]
            
            // Appliquer softmax si n√©cessaire
            val softmaxProbs = softmax(probabilities)
            
            // Trouver la classe avec la plus haute probabilit√©
            val maxIndex = softmaxProbs.indices.maxByOrNull { softmaxProbs[it] } ?: 0
            val confidence = softmaxProbs[maxIndex]
            
            val name = if (maxIndex < labels.size) {
                labels[maxIndex]
            } else {
                "Inconnu"
            }
            
            Log.d(TAG, "Reconnaissance: $name (confiance: ${confidence * 100}%)")
            
            return RecognitionResult(
                name = name,
                confidence = confidence,
                classIndex = maxIndex
            )
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erreur lors de la reconnaissance: ${e.message}", e)
            return null
        }
    }
    
    /**
     * Applique la fonction softmax pour obtenir des probabilit√©s
     */
    private fun softmax(logits: FloatArray): FloatArray {
        val maxLogit = logits.maxOrNull() ?: 0f
        val expValues = logits.map { exp((it - maxLogit).toDouble()).toFloat() }
        val sumExp = expValues.sum()
        return expValues.map { it / sumExp }.toFloatArray()
    }
    
    /**
     * Lib√®re les ressources
     */
    fun close() {
        interpreter?.close()
        interpreter = null
        Log.d(TAG, "‚úì Mod√®le ferm√©")
    }
}
