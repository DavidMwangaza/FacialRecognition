package com.example.facerecognition.ml

import android.content.Context
import android.graphics.Bitmap
import android.util.Log
import com.google.gson.Gson
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.support.common.FileUtil
import java.io.BufferedReader
import java.io.InputStreamReader
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlin.math.exp
import kotlin.math.sqrt

/**
 * Classe pour g√©rer l'inf√©rence du mod√®le TensorFlow Lite
 * Reconnaissance faciale hors ligne
 */
class FaceRecognitionModel(private val context: Context) {
    
    private var interpreter: Interpreter? = null
    private var embeddingExtractor: EmbeddingExtractor? = null
    private var labels: List<String> = emptyList()
    private var inputShape: IntArray = intArrayOf(1, 512)
    private var outputShape: IntArray = intArrayOf(1, 2)
    
    companion object {
        private const val TAG = "FaceRecognitionModel"
        private const val MODEL_FILE = "face_recognition_model.tflite"
        private const val METADATA_FILE = "face_recognition_metadata.json"
        private const val BATCH_SIZE = 1
        private const val EMBEDDING_SIZE = 512
    }
    
    data class ModelMetadata(
        val names: List<String>,
        val num_classes: Int,
        val input_shape: List<Int>,
        val model_type: String
    )
    
    data class RecognitionResult(
        val name: String,
        val confidence: Float,
        val classIndex: Int
    )
    
    init {
        try {
            loadModel()
            loadMetadata()
            
            // Initialiser l'extracteur d'embeddings r√©el
            embeddingExtractor = EmbeddingExtractor(context)
            if (!embeddingExtractor!!.initialize()) {
                Log.e(TAG, "Echec initialisation EmbeddingExtractor, extracteur indisponible")
                embeddingExtractor = null
            } else {
                Log.d(TAG, "EmbeddingExtractor (MobileFaceNet) initialis√© avec succ√®s")
            }
        } catch (e: Exception) {
            Log.e(TAG, "Erreur critique lors de l'initialisation du mod√®le", e)
            throw RuntimeException("Impossible d'initialiser FaceRecognitionModel: ${e.message}", e)
        }
    }
    
    /**
     * Charge le mod√®le TensorFlow Lite
     */
    private fun loadModel() {
        try {
            Log.d(TAG, "Chargement du mod√®le: $MODEL_FILE")
            
            // V√©rifier que le fichier existe
            val assetFiles = context.assets.list("") ?: emptyArray()
            Log.d(TAG, "Fichiers assets disponibles: ${assetFiles.joinToString()}")
            
            val options = Interpreter.Options().apply {
                setNumThreads(4)
                setUseNNAPI(true) // Utiliser Neural Networks API si disponible
            }
            
            val modelBuffer = FileUtil.loadMappedFile(context, MODEL_FILE)
            Log.d(TAG, "Buffer mod√®le charg√©: ${modelBuffer.capacity()} bytes")
            
            interpreter = Interpreter(modelBuffer, options)
            Log.d(TAG, "‚úì Interpreter cr√©√©")
            
            // R√©cup√©rer les dimensions du mod√®le
            val inputTensor = interpreter?.getInputTensor(0)
            val outputTensor = interpreter?.getOutputTensor(0)
            
            inputShape = inputTensor?.shape() ?: inputShape
            outputShape = outputTensor?.shape() ?: outputShape
            
            Log.d(TAG, "‚úì Mod√®le charg√© avec succ√®s")
            Log.d(TAG, "  Input shape: ${inputShape.contentToString()}")
            Log.d(TAG, "  Output shape: ${outputShape.contentToString()}")
            
        } catch (e: Exception) {
            Log.e(TAG, "Erreur lors du chargement du mod√®le: ${e.message}", e)
            e.printStackTrace()
            throw e // Propager l'erreur pour qu'elle soit visible
        }
    }
    
    /**
     * Charge les m√©tadonn√©es (noms des classes)
     */
    private fun loadMetadata() {
        try {
            Log.d(TAG, "üìã Chargement m√©tadonn√©es: $METADATA_FILE")
            
            val jsonString = context.assets.open(METADATA_FILE).use { inputStream ->
                BufferedReader(InputStreamReader(inputStream)).use { reader ->
                    reader.readText()
                }
            }
            
            Log.d(TAG, "JSON lu: $jsonString")
            
            val gson = Gson()
            val metadata = gson.fromJson(jsonString, ModelMetadata::class.java)
            
            labels = metadata.names
            
            Log.d(TAG, "‚úì M√©tadonn√©es charg√©es")
            Log.d(TAG, "  Nombre de classes: ${labels.size}")
            Log.d(TAG, "  Labels: $labels")
            
        } catch (e: Exception) {
            Log.e(TAG, "Erreur lors du chargement des m√©tadonn√©es: ${e.message}", e)
            e.printStackTrace()
            // Labels par d√©faut si √©chec
            labels = List(outputShape[1]) { "Personne $it" }
        }
    }
    
    /**
     * Extrait un embedding 512D depuis une image de visage via MobileFaceNet.
     * Retourne null si l'extracteur n'est pas disponible ou en cas d'erreur.
     */
    private fun extractEmbedding(bitmap: Bitmap): FloatArray? {
        val extractedEmbedding = embeddingExtractor?.extract(bitmap)
        return if (extractedEmbedding != null) {
            Log.d(TAG, "‚úì Embedding extrait par MobileFaceNet")
            extractedEmbedding
        } else {
            Log.e(TAG, "EmbeddingExtractor indisponible ou mod√®le non charg√©")
            null
        }
    }
    
    /**
     * Effectue la reconnaissance faciale √† partir d'une image
     */
    fun recognize(faceBitmap: Bitmap): RecognitionResult? {
        if (interpreter == null) {
            Log.e(TAG, "Mod√®le non charg√©")
            return null
        }
        
        try {
            // Extraire l'embedding de l'image
            val embedding = extractEmbedding(faceBitmap)
            if (embedding == null) {
                Log.e(TAG, "Reconnaissance impossible: embedding non disponible")
                return null
            }
            
            // Cr√©er le buffer d'entr√©e
            val inputBuffer = ByteBuffer.allocateDirect(BATCH_SIZE * EMBEDDING_SIZE * 4)
            inputBuffer.order(ByteOrder.nativeOrder())
            for (value in embedding) {
                inputBuffer.putFloat(value)
            }
            
            // Pr√©parer le buffer de sortie
            val numClasses = outputShape[1]
            val outputBuffer = Array(BATCH_SIZE) { FloatArray(numClasses) }
            
            // Ex√©cuter l'inf√©rence
            interpreter?.run(inputBuffer, outputBuffer)
            
            // Analyser les r√©sultats
            val probabilities = outputBuffer[0]
            
            // Appliquer softmax si n√©cessaire
            val softmaxProbs = softmax(probabilities)
            
            // Trouver la classe avec la plus haute probabilit√©
            val maxIndex = softmaxProbs.indices.maxByOrNull { softmaxProbs[it] } ?: 0
            val confidence = softmaxProbs[maxIndex]
            
            val name = if (maxIndex < labels.size) {
                labels[maxIndex]
            } else {
                "Inconnu"
            }
            
            Log.d(TAG, "Reconnaissance: $name (confiance: ${confidence * 100}%)")
            
            return RecognitionResult(
                name = name,
                confidence = confidence,
                classIndex = maxIndex
            )
            
        } catch (e: Exception) {
            Log.e(TAG, "Erreur lors de la reconnaissance: ${e.message}", e)
            return null
        }
    }
    
    /**
     * Applique la fonction softmax pour obtenir des probabilit√©s
     */
    private fun softmax(logits: FloatArray): FloatArray {
        val maxLogit = logits.maxOrNull() ?: 0f
        val expValues = logits.map { exp((it - maxLogit).toDouble()).toFloat() }
        val sumExp = expValues.sum()
        return expValues.map { it / sumExp }.toFloatArray()
    }
    
    /**
     * Lib√®re les ressources
     */
    fun close() {
        interpreter?.close()
        interpreter = null
        
        embeddingExtractor?.close()
        embeddingExtractor = null
        
        Log.d(TAG, "‚úì Mod√®le et extracteur ferm√©s")
    }
}
